{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading all the Images from URLs from Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import constants\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import time\n",
    "from time import time as timer\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import requests\n",
    "import urllib\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_mistake(unit):\n",
    "    if unit in constants.allowed_units:\n",
    "        return unit\n",
    "    if unit.replace('ter', 'tre') in constants.allowed_units:\n",
    "        return unit.replace('ter', 'tre')\n",
    "    if unit.replace('feet', 'foot') in constants.allowed_units:\n",
    "        return unit.replace('feet', 'foot')\n",
    "    return unit\n",
    "\n",
    "def parse_string(s):\n",
    "    s_stripped = \"\" if s==None or str(s)=='nan' else s.strip()\n",
    "    if s_stripped == \"\":\n",
    "        return None, None\n",
    "    pattern = re.compile(r'^-?\\d+(\\.\\d+)?\\s+[a-zA-Z\\s]+$')\n",
    "    if not pattern.match(s_stripped):\n",
    "        raise ValueError(\"Invalid format in {}\".format(s))\n",
    "    parts = s_stripped.split(maxsplit=1)\n",
    "    number = float(parts[0])\n",
    "    unit = common_mistake(parts[1])\n",
    "    if unit not in constants.allowed_units:\n",
    "        raise ValueError(\"Invalid unit [{}] found in {}. Allowed units: {}\".format(\n",
    "            unit, s, constants.allowed_units))\n",
    "    return number, unit\n",
    "\n",
    "\n",
    "def create_placeholder_image(image_save_path):\n",
    "    try:\n",
    "        placeholder_image = Image.new('RGB', (100, 100), color='black')\n",
    "        placeholder_image.save(image_save_path)\n",
    "    except Exception as e:\n",
    "        return\n",
    "\n",
    "def download_image(image_link, save_folder, retries=3, delay=3):\n",
    "    if not isinstance(image_link, str):\n",
    "        return\n",
    "\n",
    "    filename = Path(image_link).name\n",
    "    image_save_path = os.path.join(save_folder, filename)\n",
    "\n",
    "    if os.path.exists(image_save_path):\n",
    "        return\n",
    "\n",
    "    for _ in range(retries):\n",
    "        try:\n",
    "            urllib.request.urlretrieve(image_link, image_save_path)\n",
    "            return\n",
    "        except:\n",
    "            time.sleep(delay)\n",
    "    \n",
    "    create_placeholder_image(image_save_path) #Create a black placeholder image for invalid links/images\n",
    "\n",
    "def download_images(image_links, download_folder, allow_multiprocessing=True):\n",
    "    if not os.path.exists(download_folder):\n",
    "        os.makedirs(download_folder)\n",
    "\n",
    "    if allow_multiprocessing:\n",
    "        download_image_partial = partial(\n",
    "            download_image, save_folder=download_folder, retries=3, delay=3)\n",
    "\n",
    "        with multiprocessing.Pool(64) as pool:\n",
    "            list(tqdm(pool.imap(download_image_partial, image_links), total=len(image_links)))\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "    else:\n",
    "        for image_link in tqdm(image_links, total=len(image_links)):\n",
    "            download_image(image_link, save_folder=download_folder, retries=3, delay=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER = '../dataset/'\n",
    "train = pd.read_csv(os.path.join(DATASET_FOLDER, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(DATASET_FOLDER, 'test.csv'))\n",
    "sample_test = pd.read_csv(os.path.join(DATASET_FOLDER, 'sample_test.csv'))\n",
    "sample_test_out = pd.read_csv(os.path.join(DATASET_FOLDER, 'sample_test_out.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER = '../dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Sanity check using src/sanity.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python sanity.py --test_filename ../dataset/sample_test.csv --output_filename ../dataset/sample_test_out.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python sanity.py --test_filename ../dataset/sample_test.csv --output_filename ../dataset/sample_test_out_fail.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import download_images\n",
    "download_images(sample_test['image_link'], '../images/sample_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import download_images\n",
    "download_images(test['image_link'], '../images/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import download_images\n",
    "download_images(train['image_link'], '../images/train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Text from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import requests\n",
    "import multiprocessing\n",
    "import time\n",
    "from time import time as timer\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import requests\n",
    "import urllib\n",
    "from PIL import Image\n",
    "import csv\n",
    "\n",
    "# installing the libraries\n",
    "\n",
    "# !pip install pytesseract\n",
    "import re\n",
    "import pytesseract\n",
    "import cv2\n",
    "\n",
    "\n",
    "#Function for preprocessing ad saving the images\n",
    "\n",
    "\n",
    "def process_and_save_images(directory_path, csv_output_path):\n",
    "    # Initialize lists to hold processed images\n",
    "    gray_images = []\n",
    "    bw_images = []\n",
    "    processed_images = []\n",
    "    image_files = []\n",
    "\n",
    "    # Define paths for saving processed images\n",
    "    gray_save_dir = '/kaggle/working/gray_images/'\n",
    "    bw_save_dir = '/kaggle/working/bw_images/'\n",
    "    processed_save_dir = '/kaggle/working/processed_images/'\n",
    "    \n",
    "    # Ensure the save directories exist\n",
    "    os.makedirs(gray_save_dir, exist_ok=True)\n",
    "    os.makedirs(bw_save_dir, exist_ok=True)\n",
    "    os.makedirs(processed_save_dir, exist_ok=True)\n",
    "\n",
    "    # Get all jpg image files from the directory\n",
    "    for image_file in Path(directory_path).glob('*.jpg'):\n",
    "        image_files.append(image_file)\n",
    "    \n",
    "    # Prepare the CSV file for writing\n",
    "    with open(csv_output_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(['Image Filename', 'Extracted Text'])  # Header row\n",
    "        \n",
    "        # Process each image file\n",
    "        for i, image_file in enumerate(image_files, start=1):\n",
    "            # Read the image\n",
    "            img = cv2.imread(str(image_file))\n",
    "            \n",
    "            # Check if the image was loaded properly\n",
    "            if img is None:\n",
    "                print(f\"Error loading image: {image_file}\")\n",
    "                continue\n",
    "            \n",
    "            # Convert the image to grayscale\n",
    "            gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            gray_images.append(gray_image)\n",
    "            gray_output_path = os.path.join(gray_save_dir, f'gray_image_{i}.jpg')\n",
    "            cv2.imwrite(gray_output_path, gray_image)\n",
    "\n",
    "            # Apply binary thresholding\n",
    "            _, bw_image = cv2.threshold(gray_image, 130, 255, cv2.THRESH_BINARY)\n",
    "            bw_images.append(bw_image)\n",
    "            bw_output_path = os.path.join(bw_save_dir, f'bw_image_{i}.jpg')\n",
    "            cv2.imwrite(bw_output_path, bw_image)\n",
    "            \n",
    "            # Noise removal on black and white image\n",
    "            kernel = np.ones((1, 1), np.uint8)\n",
    "            noise_removed = cv2.dilate(bw_image, kernel, iterations=1)\n",
    "            kernel = np.ones((1, 1), np.uint8)\n",
    "            noise_removed = cv2.erode(noise_removed, kernel, iterations=1)\n",
    "            noise_removed = cv2.morphologyEx(noise_removed, cv2.MORPH_CLOSE, kernel)\n",
    "            noise_removed = cv2.medianBlur(noise_removed, 1)\n",
    "            processed_images.append(noise_removed)\n",
    "           \n",
    "            # Save the noise-removed image\n",
    "            processed_output_path = os.path.join(processed_save_dir, f'processed_image_{i}.jpg')\n",
    "            cv2.imwrite(processed_output_path, noise_removed)\n",
    "            \n",
    "            # Extract text using PyTesseract\n",
    "            extracted_text = pytesseract.image_to_string(noise_removed)\n",
    "            extracted_text = extracted_text.strip()  # Remove leading/trailing whitespace\n",
    "            extracted_text = ' '.join(extracted_text.split())  # Replace multiple spaces/newlines with a single space\n",
    "            extracted_text = extracted_text[:1000]  # Limit text length to 1000 characters (adjust as needed)\n",
    "            \n",
    "            # Write the filename and compacted extracted text to the CSV file\n",
    "            csv_writer.writerow([image_file.name, extracted_text])\n",
    "\n",
    "# input which contains the download set of images\n",
    "dataset='../images/sample_test'\n",
    "\n",
    "#file to save the extracted text\n",
    "output ='../final_output/Train_output.xlsx'\n",
    "\n",
    "#function call\n",
    "process_and_save_images(dataset,output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract entity_value and entity_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Define the entity_name array (unique units)\n",
    "entity_units = ['centimetre', 'foot', 'gram', 'inch', 'kilogram', 'kilovolt', 'kilowatt', 'metre', \n",
    "                'microgram', 'millimetre', 'millivolt', 'pound', 'ton', 'volt', 'watt', 'yard']\n",
    "\n",
    "# Load the old dataset into a DataFrame (assume it's a CSV file, or you can modify for other formats)\n",
    "df = pd.read_csv(\"../final_output/Train_output.csv\")  # replace with your actual file path\n",
    "\n",
    "# Function to extract entity_name and value based on matching units\n",
    "def extract_entities(text, units):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    extracted_values = []\n",
    "    # Look for patterns like 'value unit' (e.g., '20CM', '50cm', '100.5 pound', etc.)\n",
    "    for unit in units:\n",
    "        # Regex to capture a number (int or float) followed by the unit (case-insensitive)\n",
    "        pattern = r\"(\\d+\\.?\\d*)\\s*(\" + re.escape(unit) + r\")\"\n",
    "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "        \n",
    "        # Store each match in \"value unit\" format as a string\n",
    "        for match in matches:\n",
    "            value, matched_unit = match\n",
    "            extracted_values.append(f\"{value} {matched_unit.lower()}\")\n",
    "    \n",
    "    # Join all extracted values into a single string, separated by commas if there are multiple\n",
    "    return \", \".join(extracted_values)\n",
    "\n",
    "# Apply the extraction function to each row in the 'Extracted Text' column\n",
    "df['extracted_entities'] = df['Extracted Text'].apply(lambda x: extract_entities(x, entity_units))\n",
    "\n",
    "# Print or save the DataFrame with the extracted entities\n",
    "print(df[['Image Filename', 'Extracted Text', 'extracted_entities']])\n",
    "\n",
    "# Optionally, save the results to a new CSV file\n",
    "df.to_csv(\"extracted_entities.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
